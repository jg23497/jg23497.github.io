"use strict";(self.webpackChunkjgulan=self.webpackChunkjgulan||[]).push([[518],{4369:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2024/02/27/chruby-error","metadata":{"permalink":"/2024/02/27/chruby-error","source":"@site/blog/2024/02-27-chruby-error/index.mdx","title":"\'Command not found\' when running chruby","description":"Following the Ruby community\u2019s advice to avoid using the system-installed Ruby instance for development, you","date":"2024-02-27T00:00:00.000Z","tags":[{"inline":true,"label":"engineering","permalink":"/tags/engineering"}],"readingTime":1.77,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"\'Command not found\' when running chruby","tags":["engineering"]},"unlisted":false,"nextItem":{"title":"Image noise reduction using DxO PhotoLab","permalink":"/2023/01/25/image-noise-reduction-using-dxo-photolab"}},"content":"Following the Ruby community\u2019s advice to avoid using the system-installed Ruby instance for development, you \\ninstall [chruby](https://github.com/postmodern/chruby) using the [official installation instructions](https://github.com/postmodern/chruby?tab=readme-ov-file#install)\\nand intend to configure your Ruby versions using [ruby-install](https://github.com/postmodern/ruby-install). After\\ninstalling chruby, you open a terminal and see the following error when running the command on your Unix-like OS\\n(Ubuntu Linux or MacOS):\\n\\n```\\n$ chruby\\nchruby: command not found\\n```\\n\\n#### What happened?\\n\\nLet\'s take a closer look at what happened. The [installation script](https://github.com/postmodern/chruby/blob/a543a35790e5528b5a67de20e78a7390f5f7606e/scripts/setup.sh#L65) automatically adds a */etc/profile.d* script at \\n*/etc/profile.d/chruby.sh*. The */etc/profile.d* scripts are themselves auto-discovered and then executed by the \\n*/etc/profile* script, which one might expect to happen upon logging in:\\n\\n```bash title=\\"Extract from Ubuntu\'s /etc/profile file\\"\\nif [ -d /etc/profile.d ]; then\\n  for i in /etc/profile.d/*.sh; do\\n    if [ -r $i ]; then\\n      . $i\\n    fi\\n  done\\n  unset i\\nfi\\n```\\n\\nHowever, */etc/profile* is invoked only for login shells. A login shell is what we use when logging in via SSH or via a TTY.\\nOur terminal instance is an interactive non-login shell and so */etc/profile* is not executed, including our new *chruby.sh* script that\\nwould have made the chruby command available to our session.\\n\\nTo make the chruby command available to an interactive shell, we must configure our shell accordingly. For Bash this involves editing the \\n*~/.bashrc* or */etc/bash.bashrc* files, which are the current user and global configuration scripts for Bash respectively:\\n\\n```bash title=\\"~/.bashrc\\"\\nsource /usr/local/share/chruby/chruby.sh\\n```\\n\\nFor ZSH on MacOS, the equivalent files would be *~/.zshrc* and */etc/zshrc*. If using a shell other than Bash or ZSH, consult the documentation\\nto ensure the correct configuration script is updated.\\n\\nCorrectly configured, we now see the following when running chruby:\\n\\n```\\n$ chruby\\n   ruby-3.3.0\\n```\\n\\n#### What next?\\n\\nAlthough the convention for Unix-like application installers is *not* to touch the user\'s data, the Google Cloud SDK installer asks users\\nwhether it should update their *~/.bashrc* file as part of the installation process:\\n\\n> Modify profile to update your $PATH and enable bash completion? (Y/n)?\\n\\nThe chruby installer could help users by offering to do the same, even if only handling the most popular shells like Bash or ZSH."},{"id":"/2023/01/25/image-noise-reduction-using-dxo-photolab","metadata":{"permalink":"/2023/01/25/image-noise-reduction-using-dxo-photolab","source":"@site/blog/2023/01-25-image-noise-reduction-using-dxo-photolab/index.mdx","title":"Image noise reduction using DxO PhotoLab","description":"Disclaimer: I am a paying user of DxO PhotoLab, but have no other association or affiliation with the company. The opinions stated here are my own and I have not been incentivized to write them.","date":"2023-01-25T00:00:00.000Z","tags":[{"inline":true,"label":"photography","permalink":"/tags/photography"}],"readingTime":2.33,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Image noise reduction using DxO PhotoLab","tags":["photography"]},"unlisted":false,"prevItem":{"title":"\'Command not found\' when running chruby","permalink":"/2024/02/27/chruby-error"},"nextItem":{"title":"Detecting regression commits using git bisect","permalink":"/2023/01/15/detecting-regression-commits-using-git-bisect"}},"content":"import { ReactCompareSlider, ReactCompareSliderImage } from \'react-compare-slider\';\\nimport ImageOne from \\"./noise-100pc.jpg\\";\\nimport ImageTwo from \\"./denoised-100pc.jpg\\";\\nimport ImageOneZoomed from \\"./noise-200pc.jpg\\";\\nimport ImageTwoZoomed from \\"./denoised-200pc.jpg\\";\\nimport Noise from \\"./noise.jpg\\";\\n\\n_Disclaimer: I am a paying user of DxO PhotoLab, but have no other association or affiliation with the company. The opinions stated here are my own and I have not been incentivized to write them._\\n\\nSome photographers enjoy the unobtrusive, film-like character that subtle image noise can add to an image, particularly for black-and-white photography. \\nIn my experience, however, many of us prefer clean and noise-free images for the same reason that we prefer clean and noise-free audio \u2014 noise distracts our senses and clouds the signal.\\n\\nFor images, noise can lead to the loss of detail and colour information. Luminance noise, which presents as random variations in pixel illumination, is easier to forgive, whereas chroma noise, which presents as random variations in pixel colour, is an unsightly distraction.\\n\\n<img align=\\"left\\" className=\\"with-margin\\" src={Noise} alt=\\"A noisy image\\" />\\n\\nRecent advancements in image sensor technology mean that noise is less of an issue than it was say a decade ago, but image noise will still be noticeable when shooting at higher ISO values and can be particularly problematic for smaller image sensors that gather smaller quantities of light such as 1-inch, Micro Four Thirds and APS-C sensors.\\n\\nUntil recently, noise reduction algorithms have been fairly rudimentary, often resulting in a noticeable loss of detail as the image details are \'smoothed out\' to hide the noise.\\nThis changed with the release of [DxO PhotoLab](https://www.dxo.com/dxo-photolab/)\'s DeepPRIME noise reduction algorithm. The exact inner workings of DxO\'s proprietary algorithm have not been disclosed by the company, however we know that\\nPhotoLab employs Artificial Intelligence in the form of a neural network that has been trained to perform the [demosaicing](https://en.wikipedia.org/wiki/Demosaicing) and denoising processes.\\n\\nIn any case, the results speak for themselves. Below is a 100% crop of a raw image taken of a Christmas elf figure in low-light conditions at ISO 1250 using my Olympus OM-D E-M1 Mark II, paired with the Olympus 25mm f1.2 PRO lens.\\nIf it is not already clear, the left side is the image processed without noise reduction and the right side is the image processed with PhotoLab\'s DeepPRIME noise reduction (v5.5).\\n\\n<ReactCompareSlider\\n  itemOne={<ReactCompareSliderImage src={ImageOne} alt=\\"Before noise reduction (100% crop)\\" />}\\n  itemTwo={<ReactCompareSliderImage src={ImageTwo} alt=\\"After noise reduction (100% crop)\\" />}\\n  className=\\"with-margin\\"\\n/>\\n\\nA further enlargement of the same crop follows:\\n\\n<ReactCompareSlider\\n  itemOne={<ReactCompareSliderImage src={ImageOneZoomed} alt=\\"Before noise reduction (200% crop)\\" />}\\n  itemTwo={<ReactCompareSliderImage src={ImageTwoZoomed} alt=\\"After noise reduction (200% crop)\\" />}\\n  className=\\"with-margin\\"\\n/>\\n\\n\\nThe reduction in noise is significant, all without any obvious loss of image detail. DeepPRIME noise reduction has been a game-changer for my Micro Four Thirds photography and I look forward to seeing what further enhnacements\\nthe team at DxO Labs can make."},{"id":"/2023/01/15/detecting-regression-commits-using-git-bisect","metadata":{"permalink":"/2023/01/15/detecting-regression-commits-using-git-bisect","source":"@site/blog/2023/01-15-detecting-regression-commits-using-git-bisect/index.mdx","title":"Detecting regression commits using git bisect","description":"Locating the commit that introduced a regression, or some undesirable change, in a codebase can be difficult. Locating the same in a frequently-changing codebase with a large number of contributors is harder again.","date":"2023-01-15T00:00:00.000Z","tags":[{"inline":true,"label":"engineering","permalink":"/tags/engineering"}],"readingTime":1.47,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Detecting regression commits using git bisect","tags":["engineering"]},"unlisted":false,"prevItem":{"title":"Image noise reduction using DxO PhotoLab","permalink":"/2023/01/25/image-noise-reduction-using-dxo-photolab"}},"content":"import VisualisationSvg from \\"./git-bisect.svg\\";\\nimport styles from \'./index.module.css\';\\n\\nLocating the commit that introduced a regression, or some undesirable change, in a codebase can be difficult. Locating the same in a frequently-changing codebase with a large number of contributors is harder again.\\n\\nFortunately [`git bisect`](https://git-scm.com/docs/git-bisect) provides a helpful tool for doing precisely this. Rather than performing a linear search of the commits, `git bisect` uses a clever binary search algorithm to locate the offending commit far more efficiently.\\n\\n<div class=\\"center with-margin\\">\\n  <VisualisationSvg className={styles.bisect} />\\n</div>\\n\\nHaving identified a commit from the past where the regression did not exist (e.g. `git checkout` a commit from say a month ago), my typical usage of `git bisect` is along the lines of:\\n\\n1. Check out the branch containing the regression and run `git bisect start`.\\n2. Label the good and bad commits: `git bisect good <commit hash>` and `git bisect bad <commit hash>`. The current commit is taken if the commit hash argument is omitted.\\n3. Bisecting commences \u2014 a candidate commit is automatically checked out and the number of revisions left to test and number of remaining steps are printed.  You can run `git bisect reset` to abort at any stage.\\n4. Check whether the regression still exists, whether this involves running an automated test or taking manual replication steps. If the candidate commit contains the regression, run `git bisect bad`, otherwise run `git bisect good`. If any search area remains, another candidate commit is automatically checked out.\\n5. Repeat #4 until the bisecting process concludes and the bad commit\'s hash is listed.\\n\\nGiven `git bisect`\'s binary search technique, the number of steps required will only increase logarithmically as the number of commits increases \u2014 this is a time-saving tool that I turn to again and again."}]}}')}}]);